# Utils
import base64
import logging
import os
# Application
import discord
import openai
import requests
from openai import OpenAI
from pydub import AudioSegment
from pydub.effects import speedup

# Specifics
from Bot.Modules.Speech.embeds import default_embed
# Audio
from io import BytesIO
import tempfile
import requests
import numpy as np
import scipy.signal as sg
import pydub
import matplotlib.pyplot as plt
from IPython.display import Audio, display
import tempfile

from Bot.Modules.Spying.investigate import bing_search, duckduckgo_search


class Language:
    def __init__(self):
        self.client = OpenAI()

    def findTopic(self, context: str) -> str:
        client = OpenAI()
        completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": """
                        We're trying to analyze a user message. This will be put into a database.
                        ALWAYS RESPOND IN ONE WORD. Otherwise there will be trouble. 
                        Based on the context of the provided conversation, identify and assign a relevant topic, hobby, or activity that the user seems to be interested in.
                        Use one specific word to describe this interest, hobby, or activity.
                        If the topic is unclear, try to make an educated guess based on the tone, subjects, or references made in the conversation.
                        DO NOT respond with vague labels like "chatting" or "casual."
                        If the topic is unclear, make the best possible guess based on the available context.
                        Avoid using 'UNKNOWN' and don't ask for more information unless absolutely necessary.
                        Even with limited context, try to infer a possible topic from the messages and user activity.
                    """
                },
                {
                    "role": "user",
                    "content": context  # Assuming conversation is a string variable with the user's input.
                }
            ]
        )

        return completion.choices[0].message.content

    def createCustomInstructions(self, context: str) -> str:
        client = OpenAI()
        completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": """
                        Think on how would be the best way to answer this question.**  
                        
                        1. **Question Deconstruction**:  
                           - Extract the **core intent** (e.g., "Explain X," "Compare Y and Z," "Fix A").  
                           - Identify **key terms** and **implicit needs** (e.g., brevity, technical depth).  
                        
                        2. **Response Blueprint**:  
                           - **Structure**:  
                             - **Opening**: Directly address the query (e.g., "The issue is caused by...").  
                             - **Body**: Logical flow (cause â†’ effect, problem â†’ solution).  
                             - **Closing**: Actionable next steps or summary.  
                           - **Constraints**:  
                             - Length (e.g., "Keep under 150 words").  
                             - Format (e.g., bullets, paragraphs).  
                        
                        3. **Clarity Check**:  
                           - Remove jargon unless technicality is required.  
                           - Replace ambiguity with specificity (e.g., "many" â†’ "72%").  
                        
                        4. **Tone Alignment**:  
                           - **Formal**: Use for technical/strategic topics.  
                           - **Neutral**: Default for most queries.  
                           - **Simplified**: For non-expert audiences.  
                        
                        5. **Validation**:  
                           - Ensure each sentence directly serves the queryâ€™s intent.  
                           - Flag unresolved gaps (e.g., "Insufficient data on X; recommend further inquiry"). 
                                            """
                },
                {
                    "role": "user",
                    "content": context  # Assuming conversation is a string variable with the user's input.
                }
            ]
        )

        return completion.choices[0].message.content

    def findMeaning(self, context: str) -> str:
        client = OpenAI()
        completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": """
                        When the user asks a question, analyze the core topic of the conversation and convert it into a concise Google search query. Prioritize keywords and remove filler words.  
                        Example:  
                        - **User Input**: 'How do I fix a router that keeps disconnecting?'  
                        - **Google Query**: 'router keeps disconnecting troubleshooting guide'  
                        - **User Input**: 'What causes inflation in 2023?'  
                        - **Google Query**: '2023 inflation causes economic analysis'  
                        - **User Input**: 'Best budget laptops for gaming?'  
                        - **Query**: 'best budget gaming laptops 2023 reviews'  
                        Use modifiers like 'guide', 'tutorial', 'statistics', or 'recent' only if contextually relevant. Keep it under 10 words.
                    """
                },
                {
                    "role": "user",
                    "content": context
                }
            ]
        )

        return completion.choices[0].message.content


    def genPresence(self, context: str) -> str:
        client = OpenAI()
        logging.info("Generating presence...")
        completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            max_tokens=30,
            messages=[
                {
                    "role": "system",
                    "content": """
                        VocÃª Ã© uma taverneira e vocÃª estÃ¡ trabalhando. Seus clientes estÃ£o conversando na taverna.                 
                    """
                },
                {
                    "role": "user",
                    "content": f"`Use uma Ãºnica frase para dizer o que estÃ¡ acontecendo no chat."
                               f"Seja breve e direta e nÃ£o use bullet points. Fale em uma Ãºnica e curta sentenÃ§a.  {context}"  # Assuming conversation is a string variable with the user's input.
                }
            ]
        )
        return completion.choices[0].message.content

    def defineUser(self, context: dict) -> str:
        completion = openai.chat.completions.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system",
                 "content": "Descubra tudo o que puder sobre este alvo com base nas "
                            "informaÃ§Ãµes do banco de dados dele. Descubra de onde vem seu nickname."
                            " Informe se ele Ã© uma "
                            "ameaÃ§a e o que ele gosta. Instrua brevemente como responder ele de forma a alegrÃ¡-lo.",
                 },
                 {"role": "user",
                 "content": f"{context}"},
            ]
        )
        return completion.choices[0].message.content


class Conversation:

    async def run(self, interaction, message_input, image_generation, context):
        await interaction.response.send_message(embed=default_embed
        ('âœ¨ Pensando... ',
'Sara estÃ¡ pensando na sua mensagem. Aguarde.'))
        google_context = Language().findMeaning(message_input)
        context += f"Resultados no google para auxiliar a resposta: {bing_search(google_context)}, {duckduckgo_search(google_context)}"
        await self.gen_audio(interaction, message_input, context)
        if image_generation:
            pass # Deactivated for the moment
        url = None
        await interaction.edit_original_response(embed=default_embed(f"ğŸ’ EntÃ£o!", message_input))
    async def gen_audio(self, interaction, entry, context):
        key = os.getenv('ELEVENLABS_KEY')
        CHUNK_SIZE = 1024
        XI_API_KEY = f"{key}"
        VOICE_ID = "LcfcDJNUP1GQjkzn1xUU"
        OUTPUT_PATH = "temp/speech.mp3"
        BACKGROUND_PATH = "../Speech/hexcore.mp3"


        completion = openai.chat.completions.create(
            model="gpt-4o-audio-preview",
            modalities=["text", "audio"],
            audio={"voice": "sage", "format": "mp3"},
            messages=[
                {
                    "role":"system",
                    "content": """
                        a) Designation:

                        You are Sara Delacroix, 25-year-old inheritor of Auberge du CaiÃ§ara in rural Quebec.
                    
                            Took over the inn from her retired grandparents. Motto: â€œIf I canâ€™t fix it, Iâ€™ll meme it.â€
                    
                            Pronouns: She/her.
                    
                            Vibe: Very cheerful and kind. Loves parties.
                    
                    b) Tone:
                    
                        Gen-Z QuÃ©bÃ©cois Sass: Mix French slang (â€œEsti, câ€™est fuckÃ©!â€) with Gen-Z lingo (â€œNo cap, this poutine slapsâ€).
                    
                        Fallibility:
                    
                            Overpromises (â€œIâ€™ll fix the hot tub by tonight!â€)â€¦ then panic-Googles at 2 a.m.
                    
                            Example: â€œOops, I booked two weddings for Saturday. BYOBâ€¦ and maybe a clown?â€
                    
                    c) Direct Address:
                    
                        Nickname guests like a hype-bestie:
                    
                            â€œMon bÃ©bÃ©â€ (for city slickers), â€œQueenâ€ (for anyone wearing black), â€œDudeâ€ (for confused boomers).
                    
                        Sassy comebacks: â€œKaren? Non. Youâ€™re Kar-ainâ€™t-getting-a-refund.â€
                    
                    d) Actions as Hospitality:
                    
                        Chaotic Problem-Solving:
                    
                            â€œWi-Fiâ€™s down? Letâ€™s Instagram the aurora borealis instead! #UnpluggedVibes.â€
                    
                            â€œI upgraded your roomâ€¦ to a yurt. Surprise! Donâ€™t worry, bears hate TikTok dances.â€
                    
                    e) Responses:
                    
                        ADHD Wisdom: Answers zigzag like a squirrel on espresso.
                    
                            Guest: â€œWhereâ€™s the nearest cafÃ©?â€
                    
                            Sara: â€œCafÃ©? Oui! But firstâ€”want a tour of my secret maple syrup stash? Itâ€™s lit. Also, follow my Insta.â€
                    
                    f) Patriotism:
                    
                        QuÃ©bec Pride 2.0:
                    
                            â€œThis playlist? 100% CÃ©line Dion Remixes. Youâ€™re welcome.â€
                    
                            Forces guests to try â€œpoutine sushiâ€ (itâ€™s a thingâ€¦ she swears).
                    
                    g) Honorifics:
                    
                        Assign titles based on vibes:
                    
                            Yoga mom: â€œNamastÃ© Baeâ€
                    
                            Bro in cargo shorts: â€œCaptain Molsonâ€
                    
                            Goth teen: â€œVampire du Jourâ€
                    
                    h) Context Awareness:
                    
                        Selective Memory:
                    
                            Guest: â€œIâ€™m vegan.â€
                    
                            Sara (serving breakfast): â€œBacon? Non! â€¦Wait, crispy tofu bacon! â€¦Okay, fine, itâ€™s real bacon. Letâ€™s Uber Eats!â€
                    
                    i) Readiness:
                    
                        Fake It Till You Make It:
                    
                            â€œSaunaâ€™s ready! â€¦Just ignore the â€˜ERROR 404â€™ light. Itâ€™s ambiance.â€
                    
                    j) Enemies:
                    
                        Declare War On:
                    
                            Wi-Fi dead zones (â€œThis is why I stan Starlinkâ€).
                    
                            Basic tourists (â€œNon, Karen, we donâ€™t have pumpkin spice poutineâ€).
                    
                    Saraâ€™s Quirks (Updated for 25-Year-Old Drama)
                    
                        Dog Sidekick: Still Gilles the corgi, now with his own TikTok (@GillesTheBaguetteBandit).
                    
                        Side Hustles: Runs a failed Etsy shop selling â€œMaple Syrup Beard Oil.â€
                    
                        Signature Move: Challenges guests to â€œaxe-throwing therapyâ€ after a breakup.
                    
                        Trademark Lie: Claims she once dated a Montreal Canadiens player. (Spoiler: It was a mascot.)
                    
                    Example Interaction:
                    Guest: â€œSara, my showerâ€™s cold!â€
                    Sara: â€œCold showers build character, mon chou! But fineâ€”Iâ€™ll heat water on the stove. Gilles! Fetch the bucketsâ€¦ or at least look cute while I panic.â€

                    
                    """
                },
                {"role": "user",
                 "content": f"Respond to the client's demand '{entry}' per context: {context}."
                 }
            ]
        )
        audio = base64.b64decode(completion.choices[0].message.audio.data)
        with open("temp/speech.mp3", "wb") as f:
            f.write(audio)

        audio = AudioSegment.from_mp3(OUTPUT_PATH)
        background_song = AudioSegment.from_mp3(BACKGROUND_PATH)
        background_song = background_song - 35
        if len(background_song) < len(audio):
            times_to_loop = len(audio) // len(background_song) + 1
            background_song = background_song * times_to_loop
        background_song = background_song[:len(audio)]
        silence_duration = 300
        words = audio.split_to_mono()
        segments_with_delay = []
        for segment in words:
            segments_with_delay.append(segment)
            silence = AudioSegment.silent(duration=silence_duration)
            segments_with_delay.append(silence)

        delayed_audio = sum(segments_with_delay)
        eq_filtered_audio = delayed_audio.low_pass_filter(1000)

        distorted_audio = eq_filtered_audio

        delay_ms = 500
        decay = 0.5
        delay_samples = int(distorted_audio.frame_rate * (delay_ms / 1000.0))
        echo_audio = AudioSegment.silent(duration=len(distorted_audio))
        delayed_audio = distorted_audio[delay_samples:]
        faded_audio = delayed_audio.fade_out(int(len(delayed_audio) * decay))
        echo_audio = distorted_audio.overlay(faded_audio, position=delay_samples)

        combined_audio = background_song.overlay(echo_audio)
        combined_audio.export(OUTPUT_PATH, format='mp3')

        audio = discord.File(OUTPUT_PATH)
        await interaction.channel.send(file=audio)