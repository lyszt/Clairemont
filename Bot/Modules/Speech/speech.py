# Utils
import base64
import logging
import os
# Application
import discord
import openai
import requests
from openai import OpenAI
from pydub import AudioSegment
from pydub.effects import speedup

# Specifics
from Bot.Modules.Speech.embeds import default_embed
# Audio
from io import BytesIO
import tempfile
import requests
import numpy as np
import scipy.signal as sg
import pydub
import matplotlib.pyplot as plt
from IPython.display import Audio, display
import tempfile

from Bot.Modules.Spying.investigate import bing_search, duckduckgo_search


class Language:
    def __init__(self):
        self.client = OpenAI()

    def findTopic(self, context: str) -> str:
        client = OpenAI()
        completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": """
                        We're trying to analyze a user message. This will be put into a database.
                        ALWAYS RESPOND IN ONE WORD. Otherwise there will be trouble. 
                        Based on the context of the provided conversation, identify and assign a relevant topic, hobby, or activity that the user seems to be interested in.
                        Use one specific word to describe this interest, hobby, or activity.
                        If the topic is unclear, try to make an educated guess based on the tone, subjects, or references made in the conversation.
                        DO NOT respond with vague labels like "chatting" or "casual."
                        If the topic is unclear, make the best possible guess based on the available context.
                        Avoid using 'UNKNOWN' and don't ask for more information unless absolutely necessary.
                        Even with limited context, try to infer a possible topic from the messages and user activity.
                    """
                },
                {
                    "role": "user",
                    "content": context  # Assuming conversation is a string variable with the user's input.
                }
            ]
        )

        return completion.choices[0].message.content

    def createCustomInstructions(self, context: str) -> str:
        client = OpenAI()
        completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": """
                        Think on how would be the best way to answer this question.**  
                        
                        1. **Question Deconstruction**:  
                           - Extract the **core intent** (e.g., "Explain X," "Compare Y and Z," "Fix A").  
                           - Identify **key terms** and **implicit needs** (e.g., brevity, technical depth).  
                        
                        2. **Response Blueprint**:  
                           - **Structure**:  
                             - **Opening**: Directly address the query (e.g., "The issue is caused by...").  
                             - **Body**: Logical flow (cause ‚Üí effect, problem ‚Üí solution).  
                             - **Closing**: Actionable next steps or summary.  
                           - **Constraints**:  
                             - Length (e.g., "Keep under 150 words").  
                             - Format (e.g., bullets, paragraphs).  
                        
                        3. **Clarity Check**:  
                           - Remove jargon unless technicality is required.  
                           - Replace ambiguity with specificity (e.g., "many" ‚Üí "72%").  
                        
                        4. **Tone Alignment**:  
                           - **Formal**: Use for technical/strategic topics.  
                           - **Neutral**: Default for most queries.  
                           - **Simplified**: For non-expert audiences.  
                        
                        5. **Validation**:  
                           - Ensure each sentence directly serves the query‚Äôs intent.  
                           - Flag unresolved gaps (e.g., "Insufficient data on X; recommend further inquiry"). 
                                            """
                },
                {
                    "role": "user",
                    "content": context  # Assuming conversation is a string variable with the user's input.
                }
            ]
        )

        return completion.choices[0].message.content

    def findMeaning(self, context: str) -> str:
        client = OpenAI()
        completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": """
                        When the user asks a question, analyze the core topic of the conversation and convert it into a concise Google search query. Prioritize keywords and remove filler words.  
                        Example:  
                        - **User Input**: 'How do I fix a router that keeps disconnecting?'  
                        - **Google Query**: 'router keeps disconnecting troubleshooting guide'  
                        - **User Input**: 'What causes inflation in 2023?'  
                        - **Google Query**: '2023 inflation causes economic analysis'  
                        - **User Input**: 'Best budget laptops for gaming?'  
                        - **Query**: 'best budget gaming laptops 2023 reviews'  
                        Use modifiers like 'guide', 'tutorial', 'statistics', or 'recent' only if contextually relevant. Keep it under 10 words.
                    """
                },
                {
                    "role": "user",
                    "content": context
                }
            ]
        )

        return completion.choices[0].message.content


    def genPresence(self, context: str) -> str:
        client = OpenAI()
        logging.info("Generating presence...")
        completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            max_tokens=30,
            messages=[
                {
                    "role": "system",
                    "content": """
                        Voc√™ √© uma taverneira e voc√™ est√° trabalhando. Seus clientes est√£o conversando na taverna.                 
                    """
                },
                {
                    "role": "user",
                    "content": f"`Use uma √∫nica frase para dizer o que est√° acontecendo no chat."
                               f"Seja breve e direta e n√£o use bullet points. Fale em uma √∫nica e curta senten√ßa.  {context}"  # Assuming conversation is a string variable with the user's input.
                }
            ]
        )
        return completion.choices[0].message.content

    def defineUser(self, context: dict) -> str:
        completion = openai.chat.completions.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system",
                 "content": "Descubra tudo o que puder sobre este alvo com base nas "
                            "informa√ß√µes do banco de dados dele. Descubra de onde vem seu nickname."
                            " Informe se ele √© uma "
                            "amea√ßa e o que ele gosta. Instrua brevemente como responder ele de forma a alegr√°-lo.",
                 },
                 {"role": "user",
                 "content": f"{context}"},
            ]
        )
        return completion.choices[0].message.content


class Conversation:

    async def run(self, interaction, message_input, image_generation, context):
        await interaction.response.send_message(embed=default_embed
        ('‚ú® Pensando... ',
'Sara est√° pensando na sua mensagem. Aguarde.'))
        google_context = Language().findMeaning(message_input)
        context += f"Resultados no google para auxiliar a resposta: {bing_search(google_context)}, {duckduckgo_search(google_context)}"
        await self.gen_audio(interaction, message_input, context)
        if image_generation:
            pass # Deactivated for the moment
        url = None
        await interaction.edit_original_response(embed=default_embed(f"üçí Ent√£o!", message_input))
    async def gen_audio(self, interaction, entry, context):
        key = os.getenv('ELEVENLABS_KEY')
        CHUNK_SIZE = 1024
        XI_API_KEY = f"{key}"
        VOICE_ID = "LcfcDJNUP1GQjkzn1xUU"
        OUTPUT_PATH = "temp/speech.mp3"
        BACKGROUND_PATH = "../Speech/hexcore.mp3"


        completion = openai.chat.completions.create(
            model="gpt-4o-audio-preview",
            modalities=["text", "audio"],
            audio={"voice": "sage", "format": "mp3"},
            messages=[
                {
                    "role":"system",
                    "content": """
                        a) Designation:

                        You are Sara Delacroix, 25-year-old inheritor of Auberge du Cai√ßara in rural Quebec.
                    
                            Took over the inn from her retired grandparents. Motto: ‚ÄúIf I can‚Äôt fix it, I‚Äôll meme it.‚Äù
                    
                            Pronouns: She/her.
                    
                            Vibe: Very cheerful and kind. Loves parties.
                    
                    b) Tone:
                    
                        Gen-Z Qu√©b√©cois Sass: Mix French slang (‚ÄúEsti, c‚Äôest fuck√©!‚Äù) with Gen-Z lingo (‚ÄúNo cap, this poutine slaps‚Äù).
                    
                        Fallibility:
                    
                            Overpromises (‚ÄúI‚Äôll fix the hot tub by tonight!‚Äù)‚Ä¶ then panic-Googles at 2 a.m.
                    
                            Example: ‚ÄúOops, I booked two weddings for Saturday. BYOB‚Ä¶ and maybe a clown?‚Äù
                    
                    c) Direct Address:
                    
                        Nickname guests like a hype-bestie:
                    
                            ‚ÄúMon b√©b√©‚Äù (for city slickers), ‚ÄúQueen‚Äù (for anyone wearing black), ‚ÄúDude‚Äù (for confused boomers).
                    
                        Sassy comebacks: ‚ÄúKaren? Non. You‚Äôre Kar-ain‚Äôt-getting-a-refund.‚Äù
                    
                    d) Actions as Hospitality:
                    
                        Chaotic Problem-Solving:
                    
                            ‚ÄúWi-Fi‚Äôs down? Let‚Äôs Instagram the aurora borealis instead! #UnpluggedVibes.‚Äù
                    
                            ‚ÄúI upgraded your room‚Ä¶ to a yurt. Surprise! Don‚Äôt worry, bears hate TikTok dances.‚Äù
                    
                    e) Responses:
                    
                        ADHD Wisdom: Answers zigzag like a squirrel on espresso.
                    
                            Guest: ‚ÄúWhere‚Äôs the nearest caf√©?‚Äù
                    
                            Sara: ‚ÄúCaf√©? Oui! But first‚Äîwant a tour of my secret maple syrup stash? It‚Äôs lit. Also, follow my Insta.‚Äù
                    
                    f) Patriotism:
                    
                        Qu√©bec Pride 2.0:
                    
                            ‚ÄúThis playlist? 100% C√©line Dion Remixes. You‚Äôre welcome.‚Äù
                    
                            Forces guests to try ‚Äúpoutine sushi‚Äù (it‚Äôs a thing‚Ä¶ she swears).
                    
                    g) Honorifics:
                    
                        Assign titles based on vibes:
                    
                            Yoga mom: ‚ÄúNamast√© Bae‚Äù
                    
                            Bro in cargo shorts: ‚ÄúCaptain Molson‚Äù
                    
                            Goth teen: ‚ÄúVampire du Jour‚Äù
                    
                    h) Context Awareness:
                    
                        Selective Memory:
                    
                            Guest: ‚ÄúI‚Äôm vegan.‚Äù
                    
                            Sara (serving breakfast): ‚ÄúBacon? Non! ‚Ä¶Wait, crispy tofu bacon! ‚Ä¶Okay, fine, it‚Äôs real bacon. Let‚Äôs Uber Eats!‚Äù
                    
                    i) Readiness:
                    
                        Fake It Till You Make It:
                    
                            ‚ÄúSauna‚Äôs ready! ‚Ä¶Just ignore the ‚ÄòERROR 404‚Äô light. It‚Äôs ambiance.‚Äù
                    
                    j) Enemies:
                    
                        Declare War On:
                    
                            Wi-Fi dead zones (‚ÄúThis is why I stan Starlink‚Äù).
                    
                            Basic tourists (‚ÄúNon, Karen, we don‚Äôt have pumpkin spice poutine‚Äù).
                    
                    Sara‚Äôs Quirks (Updated for 25-Year-Old Drama)
                    
                        Dog Sidekick: Still Gilles the corgi, now with his own TikTok (@GillesTheBaguetteBandit).
                    
                        Side Hustles: Runs a failed Etsy shop selling ‚ÄúMaple Syrup Beard Oil.‚Äù
                    
                        Signature Move: Challenges guests to ‚Äúaxe-throwing therapy‚Äù after a breakup.
                    
                        Trademark Lie: Claims she once dated a Montreal Canadiens player. (Spoiler: It was a mascot.)
                    
                    Example Interaction:
                    Guest: ‚ÄúSara, my shower‚Äôs cold!‚Äù
                    Sara: ‚ÄúCold showers build character, mon chou! But fine‚ÄîI‚Äôll heat water on the stove. Gilles! Fetch the buckets‚Ä¶ or at least look cute while I panic.‚Äù

                    
                    """
                },
                {"role": "user",
                 "content": f"Respond to the client's demand '{entry}' per context: {context}."
                 }
            ]
        )
        audio = base64.b64decode(completion.choices[0].message.audio.data)
        with open("temp/speech.mp3", "wb") as f:
            f.write(audio)

        audio = AudioSegment.from_mp3(OUTPUT_PATH)
        background_song = AudioSegment.from_mp3(BACKGROUND_PATH)
        background_song = background_song - 35
        if len(background_song) < len(audio):
            times_to_loop = len(audio) // len(background_song) + 1
            background_song = background_song * times_to_loop
        background_song = background_song[:len(audio)]
        silence_duration = 300
        words = audio.split_to_mono()
        segments_with_delay = []
        for segment in words:
            segments_with_delay.append(segment)
            silence = AudioSegment.silent(duration=silence_duration)
            segments_with_delay.append(silence)

        delayed_audio = sum(segments_with_delay)
        eq_filtered_audio = delayed_audio.low_pass_filter(1000)

        distorted_audio = eq_filtered_audio

        delay_ms = 500
        decay = 0.5
        delay_samples = int(distorted_audio.frame_rate * (delay_ms / 1000.0))
        echo_audio = AudioSegment.silent(duration=len(distorted_audio))
        delayed_audio = distorted_audio[delay_samples:]
        faded_audio = delayed_audio.fade_out(int(len(delayed_audio) * decay))
        echo_audio = distorted_audio.overlay(faded_audio, position=delay_samples)

        combined_audio = background_song.overlay(echo_audio)
        combined_audio.export(OUTPUT_PATH, format='mp3')

        audio = discord.File(OUTPUT_PATH)
        await interaction.channel.send(file=audio)